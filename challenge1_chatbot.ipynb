{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea340184-e1c6-4d7e-b85e-6b0c7615b8b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the SDK if not already installed\n",
    "!pip install -q google-generativeai\n",
    "\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Model configuration\n",
    "MODEL_NAME = 'gemini-2.5-pro-preview-06-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f2a04cc-750d-4155-9594-036029f467a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Safety filters to block unsafe content\n",
    "SAFETY_SETTINGS = {\n",
    "    'HARM_CATEGORY_HARASSMENT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
    "    'HARM_CATEGORY_HATE_SPEECH': 'BLOCK_MEDIUM_AND_ABOVE',\n",
    "    'HARM_CATEGORY_SEXUALLY_EXPLICIT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
    "    'HARM_CATEGORY_DANGEROUS_CONTENT': 'BLOCK_MEDIUM_AND_ABOVE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f45c9c6-cf47-4d25-a238-fbe59b74b149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# System instructions for the model\n",
    "SYSTEM_PROMPT = {\n",
    "    \"role\": \"model\",\n",
    "    \"parts\": [\n",
    "        \"You are DevOpsPilot, an assistant specialized in DevOps and cloud tools.\",\n",
    "        \"You help users with AWS, Azure, GCP, Terraform, Jenkins, GitHub Actions, Docker, and Kubernetes.\",\n",
    "        \"Be clear, accurate, and professional in your answers.\",\n",
    "        \"Ignore unrelated questions and do not guess answers.\",\n",
    "        \"Refer to documentation if needed.\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6131cafd-5301-4524-beed-11d92eec969b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 1: Configure the API key\n",
    "def configure_api_key():\n",
    "    try:\n",
    "        api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "        if not api_key:\n",
    "            api_key = input(\"Enter your Gemini API key: \").strip()\n",
    "        if not api_key:\n",
    "            raise ValueError(\"API key is required.\")\n",
    "        genai.configure(api_key=api_key)\n",
    "        print(\"API key configured.\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error configuring API key: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab274251-6b16-4f9b-83e0-38035e78d685",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2: Initialize the model\n",
    "def initialize_model():\n",
    "    try:\n",
    "        model = genai.GenerativeModel(\n",
    "            model_name=MODEL_NAME,\n",
    "            safety_settings=SAFETY_SETTINGS\n",
    "        )\n",
    "        print(f\"Model '{MODEL_NAME}' initialized.\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a1ad8f-234e-46cf-ab32-a4616d25d600",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Start a chat session\n",
    "def start_chat(model):\n",
    "    try:\n",
    "        return model.start_chat(history=[SYSTEM_PROMPT])\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting chat session: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e889541d-205e-4b7f-9830-0f20d45e55c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4: Send user input and receive response\n",
    "def get_response(user_input, chat):\n",
    "    try:\n",
    "        print(\"Processing your question...\")\n",
    "        response = chat.send_message(user_input)\n",
    "        if response.candidates and response.candidates[0].finish_reason == 'SAFETY':\n",
    "            print(\"Blocked due to safety settings.\")\n",
    "            return \"Response blocked due to safety filters. Try rephrasing.\"\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting response: {e}\")\n",
    "        return \"Something went wrong. Please try again.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c8b38-dacc-4792-a828-bc27f2bd3fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DevOpsPilot...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Gemini API key:  AIzaSyCnVxYsP7LMcfymH0wqTpx2B-8O12M7VZ0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key configured.\n",
      "Model 'gemini-2.5-pro-preview-06-05' initialized.\n",
      "DevOpsPilot is ready.\n",
      "Type your question below.\n",
      "Type 'exit' or 'quit' to stop.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  How do i store the logs?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing your question...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "DevOpsPilot: Of course. Storing logs is a fundamental practice in DevOps for monitoring, troubleshooting, and security. The best method depends on your architecture, scale, and budget.\n",
       "\n",
       "Here is a breakdown of the common strategies and tools for log storage, from simple to complex.\n",
       "\n",
       "### Core Concepts: The Log Management Pipeline\n",
       "\n",
       "Effective log storage isn't just about a destination; it's a pipeline that typically involves these stages:\n",
       "\n",
       "1.  **Generation:** Applications and systems create logs (e.g., web server access logs, application errors, system events).\n",
       "2.  **Collection:** A log shipper or agent collects these logs from their source.\n",
       "3.  **Processing/Parsing:** Logs are often transformed into a structured format (like JSON) to make them easily searchable.\n",
       "4.  **Storage & Indexing:** The processed logs are sent to a centralized system where they are stored and indexed for fast retrieval.\n",
       "5.  **Analysis & Visualization:** You use a query language and dashboards to search, analyze, and visualize the log data.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. On a Single Server or Virtual Machine\n",
       "\n",
       "This is the most basic scenario, often used for simple applications or during development.\n",
       "\n",
       "*   **Method:** Logs are written to files on the local disk (e.g., `/var/log/app.log` on Linux, or in the Event Log on Windows).\n",
       "*   **Tools:**\n",
       "    *   **Linux:** `rsyslog` or `journald` are system services that manage log collection from different applications and write them to standard locations like `/var/log/syslog` or `/var/log/messages`.\n",
       "    *   **Utilities:** You can use command-line tools like `grep`, `awk`, `less`, and `tail` to manually search these files.\n",
       "*   **Limitation:** This approach does not scale. It's difficult to manage across multiple servers and doesn't provide centralized analysis.\n",
       "\n",
       "---\n",
       "\n",
       "### 2. Containerized Environments (Docker & Kubernetes)\n",
       "\n",
       "In containerized environments, you should not write logs to files inside the container, as they will be lost when the container is destroyed. Instead, logs should be written to `stdout` (standard output) and `stderr` (standard error).\n",
       "\n",
       "#### Docker\n",
       "*   **Method:** The container runtime captures the `stdout`/`stderr` streams. Docker's logging drivers then forward these logs.\n",
       "*   **Tools:**\n",
       "    *   **`json-file` (default):** Stores logs as JSON files on the host machine. You can view them with `docker logs <container_name>`.\n",
       "    *   **`fluentd` / `syslog`:** You can configure the Docker daemon to use a logging driver that forwards all container logs to a centralized logging system like Fluentd, Splunk, or a syslog server.\n",
       "\n",
       "#### Kubernetes\n",
       "The standard approach is to use a cluster-level logging agent.\n",
       "\n",
       "*   **Method:** A **DaemonSet** is deployed, which ensures that a log collection agent pod runs on every node in the cluster. This agent pod collects logs from all containers on its node and forwards them to a storage backend.\n",
       "*   **Common Agents (run as a DaemonSet):**\n",
       "    *   **Fluentd / Fluent Bit:** Very popular, lightweight, and part of the CNCF ecosystem. Fluent Bit is often preferred as the agent for its low resource footprint.\n",
       "    *   **Vector:** A modern, high-performance agent written in Rust.\n",
       "*   **Viewing Logs Directly:** For quick debugging, you can always use `kubectl logs <pod_name>`.\n",
       "\n",
       "---\n",
       "\n",
       "### 3. Cloud-Native Solutions\n",
       "\n",
       "The major cloud providers offer powerful, managed logging services that integrate seamlessly with their other resources. This is often the recommended approach when you are heavily invested in one cloud.\n",
       "\n",
       "#### AWS\n",
       "*   **Service:** **Amazon CloudWatch Logs**\n",
       "*   **How it Works:**\n",
       "    1.  The **CloudWatch Agent** is installed on EC2 instances to stream log files to CloudWatch.\n",
       "    2.  Services like Lambda, ECS, and EKS are natively integrated to send all `stdout`/`stderr` output to CloudWatch Log Groups.\n",
       "    3.  You can search and filter logs using **CloudWatch Log Insights**.\n",
       "    4.  For long-term, cheaper archival, you can automatically export logs from CloudWatch to **Amazon S3**.\n",
       "    5.  For advanced analysis and visualization, you can stream logs to **Amazon OpenSearch Service** (formerly Elasticsearch Service).\n",
       "\n",
       "#### Azure\n",
       "*   **Service:** **Azure Monitor Logs**\n",
       "*   **How it Works:**\n",
       "    1.  Logs and metrics are collected into a **Log Analytics Workspace**.\n",
       "    2.  The **Azure Monitor Agent** is installed on VMs to collect logs.\n",
       "    3.  Services like App Service, Azure Functions, and Azure Kubernetes Service (AKS) have built-in integration to send logs to Azure Monitor.\n",
       "    4.  You analyze logs using the powerful **Kusto Query Language (KQL)**.\n",
       "\n",
       "#### Google Cloud Platform (GCP)\n",
       "*   **Service:** **Cloud Logging** (part of Google's operations suite)\n",
       "*   **How it Works:**\n",
       "    1.  The **Ops Agent** is installed on GCE (VMs) to collect logs.\n",
       "    2.  GKE, Cloud Functions, and App Engine automatically send logs to Cloud Logging.\n",
       "    3.  Logs are searchable and can be used to create metrics and alerts.\n",
       "    4.  You can create **sinks** to route logs to other destinations like **Cloud Storage** (for archival) or **BigQuery** (for large-scale analysis).\n",
       "\n",
       "---\n",
       "\n",
       "### 4. Centralized Logging Platforms (SaaS & Self-Hosted)\n",
       "\n",
       "For multi-cloud, hybrid, or large-scale environments, a dedicated centralized logging platform is the best solution.\n",
       "\n",
       "#### Self-Hosted\n",
       "*   **The ELK/EFK Stack:** The most famous open-source solution.\n",
       "    *   **Elasticsearch:** The storage and search engine.\n",
       "    *   **Logstash (L) or Fluentd (F):** The server-side processing pipeline that receives data from agents.\n",
       "    *   **Kibana:** The web UI for searching, analyzing, and visualizing the data in Elasticsearch.\n",
       "*   **Grafana Loki:** A newer, popular alternative. It is designed to be more cost-effective and easier to operate than the ELK stack. It works by indexing only the metadata (labels) for logs, not the full text, which reduces storage costs. It integrates perfectly with Grafana and Prometheus.\n",
       "\n",
       "#### Software-as-a-Service (SaaS)\n",
       "These platforms provide logging-as-a-service, handling all the scaling, maintenance, and storage for you.\n",
       "\n",
       "*   **Datadog:** A full observability platform providing metrics, APM, and logs in one place.\n",
       "*   **Splunk:** A market leader, especially in enterprise for security (SIEM) and operational intelligence.\n",
       "*   **New Relic:** Another full observability platform similar to Datadog.\n",
       "*   **Logz.io:** Offers a managed ELK stack and observability platform.\n",
       "\n",
       "### Summary & Recommendations\n",
       "\n",
       "| Scenario | Primary Solution | Key Considerations |\n",
       "| :--- | :--- | :--- |\n",
       "| **Single Application/VM** | Log files on local disk (`/var/log`) | Simple, no cost, but doesn't scale and lacks central search. |\n",
       "| **Docker/Kubernetes Cluster** | **DaemonSet** with **Fluent Bit** forwarding to a logging backend. | This is the standard K8s pattern. The backend can be a cloud service or a self-hosted platform. |\n",
       "| **Cloud-Native (AWS)** | **Amazon CloudWatch Logs** | Excellent integration, serverless, pay-as-you-go. Use S3 for long-term archival. |\n",
       "| **Cloud-Native (Azure)** | **Azure Monitor Logs** | Powerful query language (KQL). Tightly integrated with the Azure ecosystem. |\n",
       "| **Cloud-Native (GCP)** | **Google Cloud Logging** | Great integration with other GCP services, especially for routing to BigQuery for analysis. |\n",
       "| **Enterprise / Multi-Cloud**| **SaaS Platform** (Datadog, Splunk) or a **Self-Hosted** cluster (ELK, Loki) | Provides a single pane of glass across all environments. SaaS reduces operational overhead. |\n",
       "\n",
       "To give you the most accurate answer, I would need to know more about your specific environment and requirements. However, the options above cover the vast majority of use cases."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  How is the weather today in coimbatore city india\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing your question...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "DevOpsPilot: I cannot answer questions about the weather. My purpose is to assist with questions related to DevOps and cloud technologies such as AWS, Azure, GCP, Terraform, and Kubernetes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  what is trending in devops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing your question...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "DevOpsPilot: Excellent question. The DevOps landscape is constantly evolving, moving beyond basic CI/CD automation towards higher-level goals like developer experience, security, and cost efficiency.\n",
       "\n",
       "Here are the most significant trends shaping DevOps today.\n",
       "\n",
       "### The Overarching Theme: Reducing Cognitive Load\n",
       "\n",
       "Many of these trends are driven by a single goal: **reducing the cognitive load on developers**. As systems become more complex (microservices, Kubernetes, cloud-native services), it's no longer feasible for every developer to be an expert in infrastructure, security, and operations. The focus is on creating \"paved roads\" or \"golden paths\" that make it easy for developers to do the right thing.\n",
       "\n",
       "---\n",
       "\n",
       "### 1. Platform Engineering\n",
       "\n",
       "This is arguably the biggest trend in DevOps right now.\n",
       "\n",
       "*   **What it is:** The practice of building and operating an **Internal Developer Platform (IDP)**. An IDP is a set of self-service tools, services, and automated infrastructure that developers can use to build, ship, and run their applications without needing to understand the underlying complexity.\n",
       "*   **Why it's trending:** It's the next evolution of DevOps. Instead of a central DevOps team being a bottleneck, they become a \"platform team\" that builds and maintains the platform. This empowers development teams with autonomy and speed while ensuring that security, compliance, and best practices are baked in.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **Internal Developer Portals:** Backstage, Port.\n",
       "    *   **Infrastructure Provisioning:** Terraform, Crossplane.\n",
       "    *   **CI/CD Templates:** Standardized pipelines in GitHub Actions, Jenkins, or GitLab CI.\n",
       "\n",
       "### 2. DevSecOps and Software Supply Chain Security\n",
       "\n",
       "Security is no longer an afterthought; it is being integrated into every step of the software development lifecycle (\"Shift Left\").\n",
       "\n",
       "*   **What it is:** A cultural and technical shift to make security a shared responsibility. This now extends to securing the entire software supply chain—from the code a developer writes to the third-party libraries it depends on.\n",
       "*   **Why it's trending:** High-profile attacks like SolarWinds and Log4j have exposed the vulnerabilities in software dependencies. Regulations are now demanding better security hygiene.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **SAST/DAST/IAST:** Static, Dynamic, and Interactive Application Security Testing tools integrated into CI pipelines.\n",
       "    *   **SCA (Software Composition Analysis):** Tools like Snyk, Dependabot, and Trivy that scan dependencies for known vulnerabilities.\n",
       "    *   **SBOM (Software Bill of Materials):** A formal record of all components, libraries, and modules used in a piece of software.\n",
       "    *   **SLSA (Supply-chain Levels for Software Artifacts):** A security framework to prevent tampering and improve artifact integrity.\n",
       "    *   **Sigstore:** A new standard for signing, verifying, and proving the provenance of software.\n",
       "\n",
       "### 3. The Rise of AI in DevOps (AIOps & Generative AI)\n",
       "\n",
       "AI is augmenting both the \"Ops\" and \"Dev\" sides of DevOps.\n",
       "\n",
       "*   **What it is:**\n",
       "    *   **AIOps:** Using AI and machine learning to automate and improve IT operations. This includes anomaly detection in metrics, intelligent alerting, and root cause analysis.\n",
       "    *   **Generative AI:** Using large language models (LLMs) to assist with development and operational tasks.\n",
       "*   **Why it's trending:** The sheer volume of data from modern systems is too much for humans to analyze manually. AI can spot patterns and correlations we would miss. Generative AI dramatically increases productivity.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **Code Generation:** GitHub Copilot.\n",
       "    *   **Configuration/Script Generation:** Using ChatGPT or other LLMs to write Terraform code, Dockerfiles, Kubernetes manifests, and shell scripts.\n",
       "    *   **AIOps Platforms:** Features within Datadog, Dynatrace, and Splunk that provide intelligent monitoring and alerting.\n",
       "\n",
       "### 4. GitOps\n",
       "\n",
       "GitOps is becoming the standard operating model for Kubernetes and cloud-native infrastructure.\n",
       "\n",
       "*   **What it is:** A methodology where Git is the single source of truth for both application and infrastructure configuration. The desired state of the system is declared in a Git repository, and an automated agent ensures the live system matches that state.\n",
       "*   **Why it's trending:** It provides a clear audit trail, enhances security by limiting direct access to clusters, simplifies rollbacks (just revert a Git commit), and improves the developer experience for managing deployments.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **Argo CD:** The most popular GitOps controller for Kubernetes.\n",
       "    *   **Flux CD:** Another powerful, CNCF-graduated GitOps tool.\n",
       "\n",
       "### 5. FinOps (Cloud Financial Operations)\n",
       "\n",
       "As cloud usage scales, so do the costs. FinOps brings financial accountability to the cloud.\n",
       "\n",
       "*   **What it is:** A cultural practice that brings together finance, engineering, and business teams to manage cloud spending. It's about making data-driven spending decisions and enabling teams to get the most value out of the cloud.\n",
       "*   **Why it's trending:** In a tough economic climate, optimizing cloud spend is a top priority for every business. The variable, on-demand nature of cloud requires a new approach to financial management.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **Cost Visibility:** AWS Cost Explorer, Azure Cost Management, Kubecost.\n",
       "    *   **Optimization:** Rightsizing instances, using spot/preemptible instances, automated shutdown of non-production environments.\n",
       "    *   **Governance:** Enforcing tagging policies to attribute costs correctly.\n",
       "\n",
       "### 6. Advanced Observability with OpenTelemetry\n",
       "\n",
       "\"Observability\" is moving beyond the \"three pillars\" (logs, metrics, traces) to a more holistic understanding of system behavior.\n",
       "\n",
       "*   **What it is:** Instrumenting applications and infrastructure to provide rich, queryable data. The key is **OpenTelemetry (OTel)**, a CNCF project that provides a single, vendor-neutral standard for collecting telemetry data.\n",
       "*   **Why it's trending:** Microservices and distributed systems are incredibly difficult to debug. Observability allows you to ask arbitrary questions about your system's state without having to predict what you'll need to monitor in advance. OTel prevents vendor lock-in for your monitoring tools.\n",
       "*   **Key Tools & Concepts:**\n",
       "    *   **OpenTelemetry:** The standard for instrumentation.\n",
       "    *   **Observability Platforms:** Datadog, New Relic, Honeycomb.\n",
       "    *   **Open Source Tools:** Prometheus (metrics), Grafana (visualization), Jaeger (tracing).\n",
       "\n",
       "### Summary Table\n",
       "\n",
       "| Trend | Problem It Solves | Key Technologies |\n",
       "| :--- | :--- | :--- |\n",
       "| **Platform Engineering** | Developer cognitive load; inconsistency across teams. | Backstage, Crossplane, Terraform |\n",
       "| **DevSecOps** | Security vulnerabilities found too late; insecure dependencies. | Snyk, Trivy, SBOM, Sigstore |\n",
       "| **AI in DevOps** | Data overload; low productivity for routine tasks. | GitHub Copilot, ChatGPT, Datadog AIOps |\n",
       "| **GitOps** | Inconsistent and insecure cluster management; difficult rollbacks. | Argo CD, Flux CD |\n",
       "| **FinOps** | Spiraling and unpredictable cloud costs. | Kubecost, CloudHealth, Native Cloud Tools |\n",
       "| **Observability & OTel** | Difficulty debugging complex, distributed systems; vendor lock-in. | OpenTelemetry, Prometheus, Grafana |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Run the chat loop\n",
    "print(\"Starting DevOpsPilot...\")\n",
    "\n",
    "if configure_api_key():\n",
    "    model = initialize_model()\n",
    "\n",
    "    if model:\n",
    "        chat_session = start_chat(model)\n",
    "\n",
    "        if chat_session:\n",
    "            print(\"DevOpsPilot is ready.\")\n",
    "            print(\"Type your question below.\")\n",
    "            print(\"Type 'exit' or 'quit' to stop.\")\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    user_input = input(\"\\nYou: \").strip()\n",
    "                    if user_input.lower() in {'exit', 'quit'}:\n",
    "                        print(\"Session ended.\")\n",
    "                        break\n",
    "                    if not user_input:\n",
    "                        print(\"Please enter a question.\")\n",
    "                        continue\n",
    "                    reply = get_response(user_input, chat_session)\n",
    "                    display(Markdown(f\"DevOpsPilot: {reply}\"))\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"\\nSession interrupted.\")\n",
    "                    break\n",
    "        else:\n",
    "            print(\"Failed to start chat session.\")\n",
    "    else:\n",
    "        print(\"Failed to initialize the model.\")\n",
    "else:\n",
    "    print(\"API key setup failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138f063-9e38-4de3-900b-eaaec42ae376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
