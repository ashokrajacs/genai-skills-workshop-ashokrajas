{
  "cells": [
    {
      "cell_type": "code",
      "id": "Dt8ytCoh8iHarSPhhZqrko6e",
      "metadata": {
        "tags": [],
        "id": "Dt8ytCoh8iHarSPhhZqrko6e"
      },
      "source": [
        "# Install necessary packages\n",
        "!pip install --upgrade google-cloud-bigquery --quiet\n",
        "!pip install --upgrade google-generativeai --quiet"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from google.cloud import bigquery\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "1t1EMXBke5cg"
      },
      "id": "1t1EMXBke5cg",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add project id\n",
        "project_id = \"qwiklabs-gcp-03-09074de52727\""
      ],
      "metadata": {
        "id": "3HPTnyx5e8iT"
      },
      "id": "3HPTnyx5e8iT",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize BigQuery client\n",
        "try:\n",
        "    bq_client = bigquery.Client(project=project_id)\n",
        "    print(f\"BigQuery client initialized \")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to initialize BigQuery client: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o65uxgPHfCzV",
        "outputId": "d60a8d17-8d11-4e37-f00d-fad136cb763a"
      },
      "id": "o65uxgPHfCzV",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery client initialized \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Gemini API Key from environment or prompt\n",
        "try:\n",
        "    api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
        "    if not api_key:\n",
        "        api_key = input(\"Enter your Gemini API key: \").strip()\n",
        "\n",
        "    if not api_key:\n",
        "        raise ValueError(\"Gemini API key is required.\")\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"Gemini API configured successfully.\")\n",
        "\n",
        "    # Initialize the model with default settings\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-pro-preview-06-05\")\n",
        "    print(\"Gemini model initialized.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Gemini setup failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIHVGmHVfGUC",
        "outputId": "24d691cc-0c27-4231-b6f8-360d5bcd08d4"
      },
      "id": "UIHVGmHVfGUC",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Gemini API key: AIzaSyCnVxYsP7LMcfymH0wqTpx2B-8O12M7VZ0\n",
            "Gemini API configured successfully.\n",
            "Gemini model initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        # User input\n",
        "        user_input = input(\"ðŸ‘¤ You: \").strip()\n",
        "\n",
        "        # Exit condition\n",
        "        if user_input.lower() in {\"quit\", \"exit\"}:\n",
        "            print(\"\\n session is closed \")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            print(\"Please enter a valid question.\")\n",
        "            continue\n",
        "\n",
        "        # ------------------------------\n",
        "        # ðŸ”Ž Step 3: Run BigQuery Vector Search\n",
        "        # ------------------------------\n",
        "        query = f\"\"\"\n",
        "        SELECT\n",
        "            query.query,\n",
        "            base.content\n",
        "        FROM\n",
        "            VECTOR_SEARCH(\n",
        "                TABLE `CustomerReview.customer_reviews_embedded`,\n",
        "                'ml_generate_embedding_result',\n",
        "                (\n",
        "                    SELECT\n",
        "                        ml_generate_embedding_result,\n",
        "                        content AS query\n",
        "                    FROM\n",
        "                        ML.GENERATE_EMBEDDING(\n",
        "                            MODEL `CustomerReview.Embeddings`,\n",
        "                            (SELECT '{user_input}' AS content)\n",
        "                        )\n",
        "                ),\n",
        "                top_k => 1,\n",
        "                options => '{{\"fraction_lists_to_search\": 0.01}}'\n",
        "            );\n",
        "        \"\"\"\n",
        "\n",
        "        query_job = bq_client.query(query)\n",
        "        results = query_job.result()\n",
        "\n",
        "        context = \"\"\n",
        "        for row in results:\n",
        "            context = row.content\n",
        "            break  # Only need top result\n",
        "\n",
        "        # If no context found\n",
        "        if not context:\n",
        "            print(\"\\n  Content not found\\n\")\n",
        "            continue\n",
        "\n",
        "        display(Markdown(f\" **Retrieved Context:**\\n```\\n{context}\\n```\"))\n",
        "\n",
        "\n",
        "        # ðŸ¤– Step 4: Generate LLM Answer with Context\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "You are a helpful assistant. Answer the user's question using only the content provided below.\n",
        "If the answer is not present in the content, say \"Sorry, I don't have that information.\"\n",
        "\n",
        "Content:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{user_input}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "        # Call Gemini to generate answer\n",
        "        response = model.generate_content(prompt)\n",
        "        display(Markdown(f\"**ðŸ¤– Gemini Answer:** {response.text.strip()}\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n error: {e}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "rhsODksvfZ_V",
        "outputId": "1e494c5a-143b-4bb7-fb1a-778349ed49a4"
      },
      "id": "rhsODksvfZ_V",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ‘¤ You: how do i report a power outage\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " **Retrieved Context:**\n```\nQuestion: How do I report a power outage? Answer: Report power outages to the Aurora Bay Utilities Department at (907) 555-0101 or submit an online form on the townâ€™s utility portal.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ðŸ¤– Gemini Answer:** Report power outages to the Aurora Bay Utilities Department at (907) 555-0101 or submit an online form on the townâ€™s utility portal."
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-00-28a2024dad67 (Jun 16, 2025, 4:52:00â€¯PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}